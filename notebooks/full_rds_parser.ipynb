{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/bjg/r_html/utils/')\n",
    "from appstore_dom_selectors import *\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pyreadr\n",
    "import csv\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Configuration\n",
    "Where is your directory with .rds files? That input goes to the variable `rds_directory_full_path`\n",
    "\n",
    "Where would you like the .tsv output of this program to be? `output_filename`\n",
    "\n",
    "How many files would you like to parse before writing to disk? `dump_threshold`\n",
    "\n",
    "When testing, enter a `stop_number` to limit number of batch iterations. A positive stop number will limit iterations, while a negative stop number will parse a folder's entire contents infinitely. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The directory where your .rds files are stored\n",
    "rds_directory_full_path = Path('/Users/bjg/r_html/big_rds_input/appdescription')\n",
    "###WINDOWS PATH UNTESTED\n",
    "#rds_directory_full_path = WindowsPath('/Users/bjg/r_html/big_rds_input/appdescription')\n",
    "\n",
    "# The desired output directory. Relative path.\n",
    "output_filename = Path('../output/final_output.tsv')\n",
    "####WINDOWS PATH UNTESTED\n",
    "#output_filename = WindowsPath('output/_1st_big_run_appstore_data.tsv')\n",
    "\n",
    "#Alter this variable to change the batch size\n",
    "dump_threshold = 25\n",
    "\n",
    "# Alter this variable to increase or decrease the sample size for testing.\n",
    "# If you do not want to test, and want to run on a full data-set,\n",
    "# Comment-out lines 102-106\n",
    "stop_number = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "### File-Configurations\n",
    "output_filenum = 0\n",
    "tsv_outfile = open(output_filename, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to convert .rds file to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open RDS File Convert to HTML\n",
    "def rds_to_html(file):\n",
    "\n",
    "    f_name = os.path.join(rds_directory_full_path, file)\n",
    "    app_rds = pyreadr.read_r(f_name)\n",
    "    app_df = app_rds[None]\n",
    "    app_html = app_df.iloc[0, 0]\n",
    "\n",
    "    return app_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is for performance: Only need to grab the header once, so we can exclude a conditional in the main loop. \n",
    "\n",
    "This loop is the overall structure of the script, but it iterates once. Instead of returning a dataset, it returns the header. \n",
    "\n",
    "This code opens a directory -> Goes through all the files -> Converts them to HTML -> Creates a BeautifulSoup object for data extraction -> runs custom `get_app_data` method that returns an entry for one app. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the Field Names for TSV file\n",
    "# Just gets the first file\n",
    "fieldnames = []\n",
    "for root, dirs, files in os.walk(rds_directory_full_path):\n",
    "    for file in files:\n",
    "        f_name = os.path.join(rds_directory_full_path, file)\n",
    "        app_rds = pyreadr.read_r(f_name)\n",
    "        app_df = app_rds[None]\n",
    "        app_html = app_df.iloc[0, 0]\n",
    "        app_soup = BeautifulSoup(app_html, 'lxml')\n",
    "\n",
    "        #Get the field names\n",
    "        fieldnames = list(get_app_data(app_soup, f_name).keys())\n",
    "\n",
    "        ## Add the app identifier as a field\n",
    "        fieldnames.insert(0, 'app_id')\n",
    "\n",
    "        break\n",
    "    break\n",
    "\n",
    "# Create the TSV file\n",
    "tsv_chunk_writer = csv.DictWriter(tsv_outfile, fieldnames=fieldnames, delimiter='\\t')\n",
    "tsv_chunk_writer.writeheader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop\n",
    "\n",
    "Note that this is the same code above. But instead of outputting to a `.tsv`, dictionaries of app-data are stored in an array: `apps = []`. Once `apps` stores the variable batch size (`dump_threshold`), all parsed apps are written to disk. Note the `tsv_chunk_writer.write_row(app)` method.  \n",
    "\n",
    "The exception is legacy, and may not even occur with the updated code, where I essentially created a schema in the other DOM file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Batch 1, writing to file ...\n",
      "\n",
      "25 apps written in total.\n",
      "\n",
      "Processed Batch 2, writing to file ...\n",
      "\n",
      "50 apps written in total.\n",
      "\n",
      "Processed Batch 3, writing to file ...\n",
      "\n",
      "75 apps written in total.\n",
      "\n",
      "Processed Batch 4, writing to file ...\n",
      "\n",
      "100 apps written in total.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Read in enough files",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Read in enough files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "## Allocate list to hold all apps' data\n",
    "##\n",
    "apps = []\n",
    "\n",
    "#Parse the data\n",
    "iterations = 1\n",
    "\n",
    "for root, dirs, files in os.walk(rds_directory_full_path):\n",
    "\n",
    "    for file in files:\n",
    "\n",
    "        if '.rds' not in file:\n",
    "            print(file)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            app_identifier = file[1:]\n",
    "\n",
    "            app_html = rds_to_html(file)\n",
    "\n",
    "            app_soup = BeautifulSoup(app_html, 'lxml')\n",
    "\n",
    "            # Assign the App Identifier\n",
    "            app_data_dict = get_app_data(app_soup, f_name)\n",
    "            app_data_dict['app_id'] = app_identifier\n",
    "            apps.append(app_data_dict)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "        ## File Writing Portion\n",
    "        ##\n",
    "        ## When we have accumulated a lot of files, Append them to the TSV.\n",
    "        if len(apps) >= dump_threshold:\n",
    "\n",
    "            print(f'\\nProcessed Batch {iterations}, writing to file ...')\n",
    "\n",
    "            #Do Dump to TSV\n",
    "            for app in apps:\n",
    "\n",
    "\n",
    "\n",
    "                # Need to create new file with updated headers\n",
    "                try:\n",
    "                    tsv_chunk_writer.writerow(app)\n",
    "\n",
    "\n",
    "                # Need to create new file with updated headers\n",
    "                except:\n",
    "                    print(f'HEADER MISMATCH')\n",
    "                    tsv_outfile.close()\n",
    "                    output_filenum += 1\n",
    "                    tsv_outfile = open(output_filename + '_' + str(output_filenum) + '.tsv', 'w')\n",
    "\n",
    "                    fieldnames = list(app.keys())\n",
    "\n",
    "                    ## Add app identifier to fields\n",
    "                    fieldnames.insert(0, 'app_id')\n",
    "\n",
    "                    tsv_chunk_writer = csv.DictWriter(tsv_outfile, fieldnames=fieldnames, delimiter='\\t')\n",
    "                    tsv_chunk_writer.writeheader()\n",
    "                    tsv_chunk_writer.writerow(app)\n",
    "\n",
    "\n",
    "            print(f'\\n{dump_threshold*iterations} apps written in total.')\n",
    "            iterations += 1\n",
    "\n",
    "\n",
    "\n",
    "            #reset apps_read\n",
    "            del apps[:]\n",
    "\n",
    "            #print(f'Decrementing stop number')\n",
    "            stop_number -= 1\n",
    "\n",
    "            if stop_number == 0:\n",
    "                sys.exit('Read in enough files')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the loop is done reading files, there may still be apps in the array. Write them to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dump the remaining files if the threshold was not met exactly on the last iteration\n",
    "for app in apps:\n",
    "    tsv_chunk_writer.writerow(app)\n",
    "\n",
    "tsv_outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
